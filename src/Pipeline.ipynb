{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30HRRwSCAdKV"
      },
      "source": [
        "## Etapas\n",
        "\n",
        "1. Cria√ß√£o de features\n",
        "2. Tratamento de outliers\n",
        "3. Normaliza√ß√£o dos dados\n",
        "4. Pipeline de pr√©-processamento\n",
        "5. Separa√ß√£o em treino/teste\n",
        "7. Treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost catboost lightgbm"
      ],
      "metadata": {
        "id": "9xHVg3GhltWv",
        "outputId": "dea3c169-23c9-491b-baa4-44d7683b78ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q4F661DIPyJH"
      },
      "outputs": [],
      "source": [
        "# @title Importa√ß√£o das bibliotecas utilizadas no programa\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Carregamento do dataset\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Cria√ß√£o de features\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Normaliza√ß√£o dos dados\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Treinamento do modelo\n",
        "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier,  AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import  AdaBoostClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x-cs77oXAWpf"
      },
      "outputs": [],
      "source": [
        "# @title Carregamento do dataset\n",
        "\n",
        "github_link = \"https://github.com/mfigueireddo/ciencia-de-dados/blob/ba579573c5b8a9246ca04f7da29bc2c74c8b362c/datasets/pre-pipeline_wildfires.parquet\"\n",
        "url = github_link.replace(\"/blob/\", \"/raw/\")\n",
        "\n",
        "local_file_path = Path(\"/content/raw_wildfires.parquet\")\n",
        "\n",
        "# Faz uma requisi√ß√£o HTTP GET ao GitHub\n",
        "with requests.get(url, stream=True) as request:\n",
        "\n",
        "    request.raise_for_status() # Confere se houve √™xito\n",
        "\n",
        "    with open(local_file_path , \"wb\") as file:\n",
        "        for chunk in request.iter_content(chunk_size=1024*1024):\n",
        "            if chunk:\n",
        "                file.write(chunk)\n",
        "\n",
        "wildfires = pd.read_parquet(local_file_path,  engine=\"pyarrow\") # Leitura realizada com a engine pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o7ao2lG7rsv1"
      },
      "outputs": [],
      "source": [
        "# @title Vari√°veis globais\n",
        "\n",
        "data_column_name = 'data'\n",
        "id_column_name = 'fire_id'\n",
        "latitude_column_name = 'latitude'\n",
        "longitude_column_name = 'longitude'\n",
        "precipitation_column_name = 'precipitacao'\n",
        "max_temperature_column_name = 'temperatura_max'\n",
        "precipitation_sum_window_column_name = 'soma_precipitacao_14d'\n",
        "max_temperature_mean_column_name = 'media_temp_max_7d'\n",
        "season_column_name = 'estacao_ano_id'\n",
        "region_column_name = 'regiao_incendio'\n",
        "target_column_name = 'houve_incendio'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMEYFWulrsv1"
      },
      "source": [
        "## 1. Cria√ß√£o de features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaEXauNWrsv1"
      },
      "source": [
        "Features geradas\n",
        "- Esta√ß√£o do ano baseada no hemisf√©rio Sul (0=Ver√£o, 1=Outono, 2=Inverno, 3=Primavera)\n",
        "- Regi√£o do inc√™ndio\n",
        "- Soma da precipita√ß√£o nos √∫ltimos 14 dias\n",
        "- M√©dia de temperatura m√°xima nos √∫ltimos 7 dias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wUCqwXwyFR2O"
      },
      "outputs": [],
      "source": [
        "# @title Classe respons√°vel pela cria√ß√£o de features\n",
        "\n",
        "class FeaturesCreation(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Colunas utilizadas\n",
        "        self.m_date_column = data_column_name\n",
        "        self.m_group_column = id_column_name\n",
        "        self.m_latitude_column = latitude_column_name\n",
        "        self.m_longitude_column = longitude_column_name\n",
        "        self.m_precipitation_column = precipitation_column_name\n",
        "        self.m_max_temperature_column = max_temperature_column_name\n",
        "\n",
        "        # Par√¢metros personalizados para cria√ß√£o das features\n",
        "        self.m_precipitation_window_days = 90\n",
        "        self.m_max_temperature_window_days =90\n",
        "\n",
        "        # Par√¢metros do DBSCAN\n",
        "        self.mm_max_radiuskm = 1.0\n",
        "        self.m_min_samples = 5\n",
        "\n",
        "        # Objetos aprendidos no fit\n",
        "        self.m_dbscan = None\n",
        "        self.m_nearest_neighbors_core = None\n",
        "        self.m_core_labels = None\n",
        "        self.m_max_radius = None\n",
        "\n",
        "    # Convers√£o necess√°ria para o DBSCAN\n",
        "    @staticmethod\n",
        "    def convert_to_radians(latitude_or_longitude):\n",
        "        return np.radians(latitude_or_longitude.astype(float))\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_month_to_season(month):\n",
        "        if month in (12, 1, 2): return 0  # Inverno\n",
        "        if month in (3, 4, 5): return 1  # Primavera\n",
        "        if month in (6, 7, 8): return 2  # Ver√£o\n",
        "        return 3  # 9, 10, 11 -> Outono\n",
        "\n",
        "    def fit(self, dataframe, target=None):\n",
        "        dataframe = dataframe.copy()\n",
        "\n",
        "        # Desativa o DBSCAN caso n√£o haja latitude e longitude\n",
        "        missing_cols = [column for column in [self.m_latitude_column, self.m_longitude_column] if column not in dataframe.columns]\n",
        "        if missing_cols:\n",
        "            self.m_dbscan = None\n",
        "            self.m_nearest_neighbors_core = None\n",
        "            self.m_core_labels = None\n",
        "            self.m_max_radius = None\n",
        "            return self\n",
        "\n",
        "        latitude_or_longitude = dataframe[[self.m_latitude_column, self.m_longitude_column]].to_numpy()\n",
        "        latitude_or_longitude_radians = self.convert_to_radians(latitude_or_longitude)\n",
        "\n",
        "        earth_radius = 6371.0\n",
        "        self.m_max_radius = self.mm_max_radiuskm / earth_radius\n",
        "\n",
        "        dbscan = DBSCAN(eps=self.m_max_radius, min_samples=self.m_min_samples, metric='haversine')\n",
        "        dbscan.fit(latitude_or_longitude_radians)\n",
        "        self.m_dbscan = dbscan\n",
        "\n",
        "        # Treina um NearestNeighbors apenas nos pontos-core para atribui√ß√£o de novos pontos √† clusters existentes em transform()\n",
        "        core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n",
        "        if hasattr(dbscan, 'core_sample_indices_') and len(dbscan.core_sample_indices_) > 0:\n",
        "            core_mask[dbscan.core_sample_indices_] = True\n",
        "            core_points = latitude_or_longitude_radians[core_mask]\n",
        "            core_labels = dbscan.labels_[core_mask]\n",
        "\n",
        "            if len(core_points) > 0:\n",
        "                nearest_neighbors = NearestNeighbors(n_neighbors=1, metric='haversine')\n",
        "                nearest_neighbors.fit(core_points)\n",
        "                self.m_nearest_neighbors_core = nearest_neighbors\n",
        "                self.m_core_labels = core_labels\n",
        "            else:\n",
        "                self.m_nearest_neighbors_core = None\n",
        "                self.m_core_labels = None\n",
        "        else:\n",
        "            self.m_nearest_neighbors_core = None\n",
        "            self.m_core_labels = None\n",
        "\n",
        "        return self\n",
        "\n",
        "    # Rotula novos pontos\n",
        "    def assign_dbscanlabels(self, dataframe):\n",
        "\n",
        "        # Se n√£o tivemos lat/lon ou DBSCAN treinado, devolve NaN\n",
        "        if self.m_nearest_neighbors_core is None or self.m_core_labels is None or self.m_max_radius is None:\n",
        "            return pd.Series([-1] * len(dataframe), index=dataframe.index, dtype='int64')\n",
        "\n",
        "        latitude_or_longitude = dataframe[[self.m_latitude_column, self.m_longitude_column]].to_numpy()\n",
        "        latitude_or_longitude_radians = self.convert_to_radians(latitude_or_longitude)\n",
        "\n",
        "        # Atribui r√≥tulo do core mais pr√≥ximo, desde que dentro do raio\n",
        "        distances, indices = self.m_nearest_neighbors_core.kneighbors(latitude_or_longitude_radians, n_neighbors=1, return_distance=True)\n",
        "        distances = distances.reshape(-1)\n",
        "        indices = indices.reshape(-1)\n",
        "\n",
        "        labels = np.full(len(dataframe), -1, dtype='int64')\n",
        "        within = distances <= self.m_max_radius\n",
        "        labels[within] = self.m_core_labels[indices[within]]\n",
        "\n",
        "        return pd.Series(labels, index=dataframe.index, dtype='int64')\n",
        "\n",
        "    # Adiciona m√©dias m√≥veis e soma pro grupo de inc√™ndio\n",
        "    def add_temporal_rollings(self, dataframe):\n",
        "\n",
        "        # Ordena por grupo e tempo para garantir rolling correto\n",
        "        if self.m_group_column in dataframe.columns and self.m_date_column in dataframe.columns:\n",
        "            dataframe = dataframe.sort_values([self.m_group_column, self.m_date_column])\n",
        "        else:\n",
        "            # Se faltar algo, s√≥ ordena por data (se existir)\n",
        "            if self.m_date_column in dataframe.columns:\n",
        "                dataframe = dataframe.sort_values(self.m_date_column)\n",
        "\n",
        "        # Rolling de precipita√ß√£o (soma dos √∫ltimos 14 dias)\n",
        "        if self.m_precipitation_column in dataframe.columns:\n",
        "            dataframe[precipitation_sum_window_column_name] = (\n",
        "                dataframe.groupby(self.m_group_column, dropna=False)[self.m_precipitation_column]\n",
        "                  .rolling(self.m_precipitation_window_days, min_periods=1)\n",
        "                  .sum()\n",
        "                  .reset_index(level=0, drop=True)\n",
        "            )\n",
        "        else:\n",
        "            dataframe[precipitation_sum_window_column_name] = np.nan\n",
        "\n",
        "        # Rolling de temperatura m√°xima (m√©dia dos √∫ltimos 7 dias)\n",
        "        if self.m_max_temperature_column in dataframe.columns:\n",
        "            dataframe[max_temperature_mean_column_name] = (\n",
        "                dataframe.groupby(self.m_group_column, dropna=False)[self.m_max_temperature_column]\n",
        "                  .rolling(self.m_max_temperature_window_days, min_periods=1)\n",
        "                  .mean()\n",
        "                  .reset_index(level=0, drop=True)\n",
        "            )\n",
        "        else:\n",
        "            dataframe[max_temperature_mean_column_name] = np.nan\n",
        "\n",
        "        return dataframe\n",
        "\n",
        "    # Aplica transforma√ß√µes e cria as novas features\n",
        "    def transform(self, dataframe, target=None):\n",
        "\n",
        "        # Trabalha em DataFrame para manter nomes/√≠ndices\n",
        "        dataframe = pd.DataFrame(dataframe).copy()\n",
        "\n",
        "        # Esta√ß√£o do ano\n",
        "        if self.m_date_column in dataframe.columns:\n",
        "            # Garante dtype datetime\n",
        "            dataframe[self.m_date_column] = pd.to_datetime(dataframe[self.m_date_column], errors='coerce')\n",
        "            estacao = dataframe[self.m_date_column].dt.month.map(self.convert_month_to_season).astype('Int64')\n",
        "            dataframe[season_column_name] = estacao.astype('float').astype('Int64')  # evita problemas de NaN -> imputar depois\n",
        "            dataframe[season_column_name] = dataframe[season_column_name].astype('float')\n",
        "        else:\n",
        "            dataframe[season_column_name] = np.nan\n",
        "\n",
        "        # Regi√£o\n",
        "        if all(c in dataframe.columns for c in [self.m_latitude_column, self.m_longitude_column]):\n",
        "            dataframe[region_column_name] = self.assign_dbscanlabels(dataframe).astype('int64')\n",
        "        else:\n",
        "            dataframe[region_column_name] = -1\n",
        "\n",
        "        # Rollings temporais\n",
        "        dataframe = self.add_temporal_rollings(dataframe)\n",
        "\n",
        "        return dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSZzsKvxrsv2"
      },
      "source": [
        "### Ajustes nos dados\n",
        "\n",
        "As features esta√ß√£o do ano e regi√£o do inc√™ndio que foram criadas precisam ser tratadas.\n",
        "Isso porque seus valores s√£o categ√≥ricos e n√£o h√° rela√ß√£o num√©rica entre eles.\n",
        "Isto ser√° feito na normaliza√ß√£o dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXWH4spcYhkY"
      },
      "source": [
        "## 2. Tratamento de outliers\n",
        "\n",
        "**Transforma√ß√£o Logar√≠tmica**\n",
        "- Aplica log(x) ou log(x+constante) para valores positivos\n",
        "- Muito eficaz para dados com distribui√ß√£o assim√©trica positiva\n",
        "- Comprime valores grandes e expande valores pequenos\n",
        "- F√≥rmula: X_log = log(X + c), onde c evita log(0)\n",
        "\n",
        "**Transforma√ß√£o Raiz Quadrada**\n",
        "- Menos dr√°stica que a transforma√ß√£o logar√≠tmica\n",
        "- √ötil para dados de contagem e vari√°veis positivamente assim√©tricas\n",
        "- F√≥rmula: X_sqrt = sqrt(X)\n",
        "\n",
        "**Winsoriza√ß√£o (Capping/Clipping)**\n",
        "\n",
        "A **Winsoriza√ß√£o** √© uma t√©cnica de tratamento de outliers que **limita valores extremos** sem remov√™-los completamente. Em vez de excluir outliers, substitu√≠mos os valores extremos pelos valores de percentis espec√≠ficos.\n",
        "\n",
        "**Como funciona:**\n",
        "- Define-se limites baseados em percentis (ex: 5¬∫ e 95¬∫ percentil)\n",
        "- Valores abaixo do limite inferior s√£o substitu√≠dos pelo valor do limite inferior\n",
        "- Valores acima do limite superior s√£o substitu√≠dos pelo valor do limite superior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmhrgtvXBUL8"
      },
      "source": [
        "| Vari√°vel                                 | Melhor m√©todo         | Justificativa (1 linha)                                                                                   |\n",
        "| :--------------------------------------- | :-------------------- | :-------------------------------------------------------------------------------------------------------- |\n",
        "| **precipitacao**                         | **Log(x + 1)**        | Reduziu fortemente a assimetria (7.87 ‚Üí 2.59) e manteve os limites IQR est√°veis ‚Äî ideal para cauda longa. |\n",
        "| **umidade_relativa_max**                 | **Winsorizar 5%-5%**  | Cortou outliers (23 ‚Üí 0) e melhorou levemente a simetria; log/sqrt inflaram valores.                      |\n",
        "| **umidade_relativa_min**                 | **Winsorizar 5%-5%**  | Assimetria e outliers foram totalmente corrigidos (1155 ‚Üí 0).                                             |\n",
        "| **umidade_especifica**                   | **Sqrt**              | Melhor simetria (0.89 ‚Üí 0.16) e forte redu√ß√£o de outliers (6967 ‚Üí 2102).                                  |\n",
        "| **radiacao_solar**                       | **Sem transforma√ß√£o** | J√° sim√©trica e sem outliers; log piorou, winsor apenas repete.                                            |\n",
        "| **temperatura_min**                      | **Winsorizar 5%-5%**  | Remo√ß√£o completa de outliers (5066 ‚Üí 0) e leve ganho de simetria.                                         |\n",
        "| **temperatura_max**                      | **Winsorizar 5%-5%**  | Mesmo comportamento de `temperatura_min`.                                                                 |\n",
        "| **velocidade_vento**                     | **Log(x + 1)**        | Reduziu assimetria (1.23 ‚Üí 0.19) e outliers (8723 ‚Üí 1128) sem eliminar extremos reais.                    |\n",
        "| **indice_queima**                        | **Winsorizar 5%-5%**  | Log e sqrt aumentaram outliers via IQR; winsor eliminou-os com m√≠nima distor√ß√£o.                          |\n",
        "| **umidade_combustivel_morto_100_horas**  | **Sqrt**              | Forte queda de outliers (44 ‚Üí 9) e leve suaviza√ß√£o de forma.                                              |\n",
        "| **umidade_combustivel_morto_1000_horas** | **Sqrt**              | Reduziu outliers (373 ‚Üí 4) mantendo distribui√ß√£o coerente.                                                |\n",
        "| **componente_energia_lancada**           | **Sem transforma√ß√£o** | J√° equilibrada; transforma√ß√µes criam falsos outliers.                                                     |\n",
        "| **evapotranspiracao_real**               | **Sqrt**              | Melhorou drasticamente a simetria (0.71 ‚Üí -0.00) e reduziu outliers (3292 ‚Üí 153).                         |\n",
        "| **evapotranspiracao_potencial**          | **Log(x + 1)**        | Skew caiu (0.53 ‚Üí -0.36) e outliers zeraram (679 ‚Üí 0).                                                    |\n",
        "| **deficit_pressao_vapor**                | **Log(x + 1)**        | Alta cauda direita suavizada (1.46 ‚Üí 0.52) e outliers despencaram (14758 ‚Üí 672).                          |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CYTi9RrGQd0x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Classe respons√°vel pelo tratamento dos outliers\n",
        "\n",
        "log_columns = [\n",
        "    \"precipitacao\",\n",
        "    \"velocidade_vento\",\n",
        "    \"evapotranspiracao_potencial\",\n",
        "    \"deficit_pressao_vapor\",\n",
        "]\n",
        "sqrt_columns = [\n",
        "    \"umidade_especifica\",\n",
        "    \"umidade_combustivel_morto_100_horas\",\n",
        "    \"umidade_combustivel_morto_1000_horas\",\n",
        "    \"evapotranspiracao_real\",\n",
        "]\n",
        "winsor_columns = [\n",
        "    \"umidade_relativa_max\",\n",
        "    \"umidade_relativa_min\",\n",
        "    \"temperatura_min\",\n",
        "    \"temperatura_max\",\n",
        "    \"indice_queima\",\n",
        "]\n",
        "\n",
        "class OutliersTreatment(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.m_log_columns = log_columns\n",
        "        self.m_sqrt_columns = sqrt_columns\n",
        "        self.m_winsor_columns = winsor_columns\n",
        "        self.m_winsor_limits = (0.05, 0.05)\n",
        "\n",
        "    # Calcula par√¢metros necess√°rios para aplicar as transforma√ß√µes corretamente\n",
        "    def fit(self, dataframe, target=None):\n",
        "\n",
        "        # Garante que o usu√°rio esteja enviado um dataframe no formato correto\n",
        "        dataframe = dataframe if isinstance(dataframe, pd.DataFrame) else pd.DataFrame(dataframe)\n",
        "\n",
        "        # C√°lculo de offsets para garantir que n√£o haver√£o valores zerados ou negativos\n",
        "        # \"coerce\" convete valores inv√°lidos para NaN\n",
        "\n",
        "        self.m_log_offset = {}\n",
        "        for column in self.m_log_columns:\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                min_value = series.min()\n",
        "                self.m_log_offset[column] = (abs(min_value) + 1) if pd.notna(min_value) and min_value <= 0 else 1.0\n",
        "\n",
        "        self.m_sqrt_offset = {}\n",
        "        for column in self.m_sqrt_columns:\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                min_value = series.min()\n",
        "                self.m_sqrt_offset[column] = (abs(min_value) + 0.01) if pd.notna(min_value) and min_value < 0 else 0.0\n",
        "\n",
        "        # Garante que a winsoriza√ß√£o s√≥ seja feita com colunas que realmente est√£o no dataframe\n",
        "        actual_columns_to_winsor = [column for column in self.m_winsor_columns if column in dataframe.columns]\n",
        "        low_quantile, high_quantile = self.m_winsor_limits\n",
        "\n",
        "        if actual_columns_to_winsor:\n",
        "            # Converte cada coluna para num√©rico (coerces -> NaN) e calcula quantis por coluna\n",
        "            winsor_dataframe = dataframe[actual_columns_to_winsor].apply(pd.to_numeric, errors=\"coerce\")\n",
        "            self.m_low_quantile  = winsor_dataframe.quantile(low_quantile)\n",
        "            self.m_high_quantile = winsor_dataframe.quantile(1 - high_quantile)\n",
        "        else:\n",
        "            # garante atributos vazios para n√£o quebrar no transform()\n",
        "            self.m_low_quantile  = pd.Series(dtype=float)\n",
        "            self.m_high_quantile = pd.Series(dtype=float)\n",
        "\n",
        "        return self\n",
        "\n",
        "    # Aplica as transforma√ß√µes\n",
        "    def transform(self, dataframe):\n",
        "\n",
        "        # Garante que o usu√°rio esteja enviado o dataframe correto\n",
        "        dataframe = dataframe.copy() if isinstance(dataframe, pd.DataFrame) else pd.DataFrame(dataframe).copy()\n",
        "\n",
        "        # LOG\n",
        "        for column, offset in self.m_log_offset.items():\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                dataframe[column] = np.log(series + offset)\n",
        "\n",
        "        # SQRT\n",
        "        for column, offset in self.m_sqrt_offset.items():\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                dataframe[column] = np.sqrt(series + offset)\n",
        "\n",
        "        # Winsoriza√ß√£o\n",
        "        for column in self.m_low_quantile.index:\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                dataframe[column] = series.clip(lower=self.m_low_quantile[column], upper=self.m_high_quantile[column])\n",
        "\n",
        "        return dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpplgU1crsv4"
      },
      "source": [
        "## 3. Normaliza√ß√£o dos dados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# @title Normaliza√ß√£o dos Dados\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Carrega o dataset j√° transformado\n",
        "df = pd.read_csv('/content/drive/MyDrive/wildfires_transformed.csv')\n",
        "\n",
        "# Colunas num√©ricas a normalizar\n",
        "colunas_numericas = [\n",
        "    'precipitacao',\n",
        "    'umidade_relativa_max', 'umidade_relativa_min',\n",
        "    'umidade_especifica',\n",
        "    'radiacao_solar',\n",
        "    'temperatura_min', 'temperatura_max',\n",
        "    'velocidade_vento',\n",
        "    'indice_queima',\n",
        "    'umidade_combustivel_morto_100_horas',\n",
        "    'umidade_combustivel_morto_1000_horas',\n",
        "    'componente_energia_lancada',\n",
        "    'evapotranspiracao_real',\n",
        "    'evapotranspiracao_potencial',\n",
        "    'deficit_pressao_vapor'\n",
        "]\n",
        "\n",
        "# Aplicar Min‚ÄìMax Scaling\n",
        "scaler = MinMaxScaler()\n",
        "df_normalizado = df.copy()\n",
        "df_normalizado[colunas_numericas] = scaler.fit_transform(df[colunas_numericas])\n",
        "\n",
        "# Conferir o intervalo\n",
        "print(\"Intervalo das vari√°veis ap√≥s normaliza√ß√£o:\")\n",
        "print(df_normalizado[colunas_numericas].describe().loc[['min','max']])\n",
        "\n",
        "# Salvar dataset normalizado\n",
        "df_normalizado.to_csv('wildfires_normalized.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(\"\\n‚úÖ Normaliza√ß√£o conclu√≠da com sucesso!\")\n",
        "print(\"üìÅ Arquivo salvo como 'wildfires_normalized.csv'\")"
      ],
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMLJbzYxuqS_",
        "outputId": "b975cd56-b15e-4a2b-93c3-f293458a2994"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Intervalo das vari√°veis ap√≥s normaliza√ß√£o:\n",
            "     precipitacao  umidade_relativa_max  umidade_relativa_min  \\\n",
            "min           0.0                   0.0                   0.0   \n",
            "max           1.0                   1.0                   1.0   \n",
            "\n",
            "     umidade_especifica  radiacao_solar  temperatura_min  temperatura_max  \\\n",
            "min                 0.0             0.0              0.0              0.0   \n",
            "max                 1.0             1.0              1.0              1.0   \n",
            "\n",
            "     velocidade_vento  indice_queima  umidade_combustivel_morto_100_horas  \\\n",
            "min               0.0            0.0                                  0.0   \n",
            "max               1.0            1.0                                  1.0   \n",
            "\n",
            "     umidade_combustivel_morto_1000_horas  componente_energia_lancada  \\\n",
            "min                                   0.0                         0.0   \n",
            "max                                   1.0                         1.0   \n",
            "\n",
            "     evapotranspiracao_real  evapotranspiracao_potencial  \\\n",
            "min                     0.0                          0.0   \n",
            "max                     1.0                          1.0   \n",
            "\n",
            "     deficit_pressao_vapor  \n",
            "min                    0.0  \n",
            "max                    1.0  \n",
            "\n",
            "‚úÖ Normaliza√ß√£o conclu√≠da com sucesso!\n",
            "üìÅ Arquivo salvo como 'wildfires_normalized.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "_HM_loh1QihZ"
      },
      "outputs": [],
      "source": [
        "# @title Algoritmo de normaliza√ß√£o\n",
        "\n",
        "categoric_cols = [season_column_name, region_column_name]\n",
        "\n",
        "def numeric_columns_selector(dataframe):\n",
        "    # Seleciona colunas num√©ricas, exceto as categ√≥ricas codificadas numericamente\n",
        "    num = dataframe.select_dtypes(include='number').columns.tolist()\n",
        "    return [column for column in num if column not in categoric_cols]\n",
        "\n",
        "numeric_columns_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "categoric_columns_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
        "])\n",
        "\n",
        "DataNormalization = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numerical', numeric_columns_pipeline, numeric_columns_selector),\n",
        "        ('categoric', categoric_columns_pipeline, categoric_cols)\n",
        "    ],\n",
        "    remainder='passthrough'  # mant√©m quaisquer colunas n√£o listadas\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX-OtG5nrsv4"
      },
      "source": [
        "## 4. Pipeline de pr√©-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kyUKC9duPwYA"
      },
      "outputs": [],
      "source": [
        "# @title C√≥digo da Pipeline de pr√©-processamento\n",
        "\n",
        "preprocess = Pipeline(steps=[\n",
        "    (\"features_creation\", FeaturesCreation()),\n",
        "    (\"outliers_treatment\", OutliersTreatment()),\n",
        "    (\"data_normalization\", DataNormalization)\n",
        "])\n",
        "\n",
        "# Remove data e fire_id, al√©m de converter o dataframe para o formato esperado pelos classificadores\n",
        "def sanitize_after_preprocess(features):\n",
        "    # Transforma em numpy.ndarray\n",
        "    if isinstance(features, pd.DataFrame):\n",
        "        cols = [column for column in features.columns if column not in ('data', 'fire_id')]\n",
        "        features = features[cols]\n",
        "        features = features.select_dtypes(include='number')\n",
        "    return features\n",
        "\n",
        "sanitize = FunctionTransformer(sanitize_after_preprocess, validate=False, feature_names_out='one-to-one')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSxExLXsXrdc"
      },
      "source": [
        "## 5. Separa√ß√£o em treino/teste\n",
        "\n",
        "### Time Series Cross Validation\n",
        "\n",
        "A Time Series Cross Validation √© uma t√©cnica especializada para validar modelos quando os dados possuem ordem cronol√≥gica. Diferente das t√©cnicas tradicionais, ela respeita a estrutura temporal dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4l1XXAgXQkt7"
      },
      "outputs": [],
      "source": [
        "# @title Algoritmo de separa√ß√£o\n",
        "\n",
        "# Gera folds (train_idx, test_idx) respeitando ordem temporal por grupo, embargo em n√≠vel de grupo e exclus√£o m√∫tua treino/teste por grupo.\n",
        "def group_time_series_cross_validation():\n",
        "    dataframe = wildfires\n",
        "    time_column = data_column_name\n",
        "    group_column = id_column_name\n",
        "    folds_amount = 5\n",
        "    fold_groups_size = 1\n",
        "    gap_between_groups_amount = 0\n",
        "\n",
        "    # Ordena grupos pelo primeiro timestamp\n",
        "    first_time = (\n",
        "        dataframe[[group_column, time_column]]\n",
        "        .dropna(subset=[time_column])\n",
        "        .groupby(group_column)[time_column]\n",
        "        .min()\n",
        "        .sort_values()\n",
        "    )\n",
        "    ordered_groups = first_time.index.to_numpy()\n",
        "    ordered_groups_len = len(ordered_groups)\n",
        "\n",
        "    groups_amount_by_step = fold_groups_size\n",
        "\n",
        "    min_train_groups = max(1, fold_groups_size) # pelo menos 1\n",
        "\n",
        "    # √Çncora: √∫ltimo grupo incluso no treino\n",
        "    # Precisamos garantir espa√ßo para gap + teste √† frente\n",
        "    max_anchor = ordered_groups_len - gap_between_groups_amount - fold_groups_size\n",
        "    if max_anchor <= min_train_groups:\n",
        "        return  # n√£o h√° splits poss√≠veis\n",
        "\n",
        "    splits = 0\n",
        "    anchor = min_train_groups\n",
        "    while anchor <= max_anchor and splits < folds_amount:\n",
        "        train_groups = ordered_groups[:anchor]\n",
        "\n",
        "        test_start = anchor + gap_between_groups_amount\n",
        "        test_end = test_start + fold_groups_size\n",
        "        test_groups = ordered_groups[test_start:test_end]\n",
        "\n",
        "        train_idx = dataframe.index[dataframe[group_column].isin(train_groups)].to_numpy()\n",
        "        test_idx  = dataframe.index[dataframe[group_column].isin(test_groups)].to_numpy()\n",
        "\n",
        "        if train_idx.size and test_idx.size:\n",
        "            yield (train_idx, test_idx)\n",
        "            splits += 1\n",
        "\n",
        "        anchor += groups_amount_by_step\n",
        "\n",
        "cross_validation = cross_validation_splits = list(group_time_series_cross_validation())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp__-wd-rsv5"
      },
      "source": [
        "## 6. Treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AGUKAJ3Rrsv5",
        "outputId": "3015e0bf-70b8-48e5-c505-78d8884a487e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando modelo: Dummy (mais frequente)...\n",
            " Modelo Dummy (mais frequente) treinado com sucesso.\n",
            "\n",
            "Treinando modelo: Regress√£o Log√≠stica...\n",
            " Modelo Regress√£o Log√≠stica treinado com sucesso.\n",
            "\n",
            "Treinando modelo: √Årvore de Decis√£o...\n",
            " Modelo √Årvore de Decis√£o treinado com sucesso.\n",
            "\n",
            "Treinando modelo: Random Forest...\n",
            " Modelo Random Forest treinado com sucesso.\n",
            "\n",
            "Treinando modelo: Naive Bayes...\n",
            " Modelo Naive Bayes treinado com sucesso.\n",
            "\n",
            "Treinando modelo: KNN...\n",
            " Modelo KNN treinado com sucesso.\n",
            "\n",
            "Treinando modelo: Gradient Boosting...\n",
            " Modelo Gradient Boosting treinado com sucesso.\n",
            "\n",
            "Treinando modelo: AdaBoost...\n",
            " Modelo AdaBoost treinado com sucesso.\n",
            "\n",
            "Treinando modelo: HistGradientBoosting...\n",
            " Modelo HistGradientBoosting treinado com sucesso.\n",
            "\n",
            "Treinando modelo: RidgeClassifier...\n",
            " Modelo RidgeClassifier treinado com sucesso.\n",
            "\n",
            "Treinando modelo: MLP (Neural Net)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Modelo MLP (Neural Net) treinado com sucesso.\n",
            "\n",
            "Treinando modelo: XGBoost...\n",
            " Modelo XGBoost treinado com sucesso.\n",
            "\n",
            "Treinando modelo: CatBoost...\n",
            " Modelo CatBoost treinado com sucesso.\n",
            "\n",
            "Treinando modelo: LightGBM...\n",
            "[LightGBM] [Info] Number of positive: 10171, number of negative: 68075\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004452 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3552\n",
            "[LightGBM] [Info] Number of data points in the train set: 78246, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129987 -> initscore=-1.901070\n",
            "[LightGBM] [Info] Start training from score -1.901070\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 23751, number of negative: 132738\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015630 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3729\n",
            "[LightGBM] [Info] Number of data points in the train set: 156489, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151774 -> initscore=-1.720753\n",
            "[LightGBM] [Info] Start training from score -1.720753\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 38141, number of negative: 196591\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3742\n",
            "[LightGBM] [Info] Number of data points in the train set: 234732, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.162487 -> initscore=-1.639836\n",
            "[LightGBM] [Info] Start training from score -1.639836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Modelo LightGBM treinado com sucesso.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Modelo  Accuracy  Precision    Recall  F1-score   ROC AUC\n",
              "4              Naive Bayes  0.588798   0.188665  0.354248  0.227289  0.504112\n",
              "5                      KNN  0.784922   0.214438  0.036801  0.061151  0.501886\n",
              "2        √Årvore de Decis√£o  0.775541   0.198405  0.041659  0.059747  0.498515\n",
              "10        MLP (Neural Net)  0.781386   0.127466  0.040767  0.058487  0.501949\n",
              "6        Gradient Boosting  0.802768   0.068505  0.002476  0.004765  0.499875\n",
              "13                LightGBM  0.801678   0.046412  0.001374  0.002666  0.498769\n",
              "8     HistGradientBoosting  0.803407   0.064399  0.000845  0.001668  0.499614\n",
              "1      Regress√£o Log√≠stica  0.804404   0.036364  0.000147  0.000293  0.499947\n",
              "11                 XGBoost  0.804174   0.026847  0.000095  0.000190  0.499785\n",
              "3            Random Forest  0.804400   0.008772  0.000023  0.000046  0.499894\n",
              "0   Dummy (mais frequente)  0.804587   0.000000  0.000000  0.000000  0.500000\n",
              "7                 AdaBoost  0.804587   0.000000  0.000000  0.000000  0.500000\n",
              "9          RidgeClassifier  0.804587   0.000000  0.000000  0.000000  0.500000\n",
              "12                CatBoost  0.804587   0.000000  0.000000  0.000000  0.500000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43a6f4ef-414f-43e9-9ef9-1b19fa3dac44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>ROC AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.588798</td>\n",
              "      <td>0.188665</td>\n",
              "      <td>0.354248</td>\n",
              "      <td>0.227289</td>\n",
              "      <td>0.504112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.784922</td>\n",
              "      <td>0.214438</td>\n",
              "      <td>0.036801</td>\n",
              "      <td>0.061151</td>\n",
              "      <td>0.501886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√Årvore de Decis√£o</td>\n",
              "      <td>0.775541</td>\n",
              "      <td>0.198405</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.059747</td>\n",
              "      <td>0.498515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>MLP (Neural Net)</td>\n",
              "      <td>0.781386</td>\n",
              "      <td>0.127466</td>\n",
              "      <td>0.040767</td>\n",
              "      <td>0.058487</td>\n",
              "      <td>0.501949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.802768</td>\n",
              "      <td>0.068505</td>\n",
              "      <td>0.002476</td>\n",
              "      <td>0.004765</td>\n",
              "      <td>0.499875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.801678</td>\n",
              "      <td>0.046412</td>\n",
              "      <td>0.001374</td>\n",
              "      <td>0.002666</td>\n",
              "      <td>0.498769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>0.803407</td>\n",
              "      <td>0.064399</td>\n",
              "      <td>0.000845</td>\n",
              "      <td>0.001668</td>\n",
              "      <td>0.499614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regress√£o Log√≠stica</td>\n",
              "      <td>0.804404</td>\n",
              "      <td>0.036364</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000293</td>\n",
              "      <td>0.499947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.804174</td>\n",
              "      <td>0.026847</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.499785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.804400</td>\n",
              "      <td>0.008772</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.499894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dummy (mais frequente)</td>\n",
              "      <td>0.804587</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.804587</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.804587</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.804587</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43a6f4ef-414f-43e9-9ef9-1b19fa3dac44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43a6f4ef-414f-43e9-9ef9-1b19fa3dac44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43a6f4ef-414f-43e9-9ef9-1b19fa3dac44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-50353739-ab0e-4baa-9e8b-8c7711548b2a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50353739-ab0e-4baa-9e8b-8c7711548b2a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-50353739-ab0e-4baa-9e8b-8c7711548b2a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f7a22d00-a4bd-4d49-881d-29b806b9901b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_resultados')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f7a22d00-a4bd-4d49-881d-29b806b9901b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_resultados');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_resultados",
              "summary": "{\n  \"name\": \"df_resultados\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"Random Forest\",\n          \"AdaBoost\",\n          \"Naive Bayes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056945674407313296,\n        \"min\": 0.5887981459470283,\n        \"max\": 0.804587417830775,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.8016776793664183,\n          0.5887981459470283,\n          0.8043999676222366\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07925930574484297,\n        \"min\": 0.0,\n        \"max\": 0.21443824526918873,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.04641158855816621,\n          0.18866529748778585,\n          0.008771929824561403\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09360405463902564,\n        \"min\": 0.0,\n        \"max\": 0.35424849595617586,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.001374246352144807,\n          0.35424849595617586,\n          2.316423442205235e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.062044437497583906,\n        \"min\": 0.0,\n        \"max\": 0.22728888168953224,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.002666076749119888,\n          0.22728888168953224,\n          4.62064504204787e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0014374111418655048,\n        \"min\": 0.49851453895194925,\n        \"max\": 0.5041115485991473,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.4987687310468574,\n          0.5041115485991473,\n          0.49989438640170736\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Dataset\n",
        "wildfires = pd.read_csv('/content/drive/MyDrive/outliers_wildfires.csv')\n",
        "wildfires['data'] = pd.to_datetime(wildfires['data'], errors='coerce')\n",
        "wildfires = wildfires.sort_values('data').reset_index(drop=True)\n",
        "\n",
        "X = wildfires.drop(columns=[\"houve_incendio\", \"data\", \"fire_id\"])\n",
        "y = wildfires[\"houve_incendio\"].astype(int)\n",
        "\n",
        "# Modelos conforme aula (sem hiperpar√¢metros avan√ßados)\n",
        "# üîß Aperfei√ßoamento dos modelos (baseado nas aulas)\n",
        "\n",
        "modelos = {\n",
        "    # Baseline simples\n",
        "    \"Dummy (mais frequente)\": DummyClassifier(strategy=\"most_frequent\"),\n",
        "\n",
        "    # Regress√£o Log√≠stica - com regulariza√ß√£o L2 leve\n",
        "    \"Regress√£o Log√≠stica\": LogisticRegression(\n",
        "        C=0.5, penalty='l2', solver='liblinear', max_iter=2000\n",
        "    ),\n",
        "\n",
        "    # √Årvore de Decis√£o - controlando profundidade e tamanho de folha\n",
        "    \"√Årvore de Decis√£o\": DecisionTreeClassifier(\n",
        "        max_depth=8, min_samples_split=4, min_samples_leaf=2, random_state=42\n",
        "    ),\n",
        "\n",
        "    # Random Forest - mais √°rvores e profundidade moderada\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=150, max_depth=10, min_samples_split=5,\n",
        "        random_state=42, n_jobs=-1\n",
        "    ),\n",
        "\n",
        "    # Naive Bayes - suaviza√ß√£o leve (mais est√°vel)\n",
        "    \"Naive Bayes\": GaussianNB(var_smoothing=1e-8),\n",
        "\n",
        "    # KNN - mais vizinhos e dist√¢ncia ponderada\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=7, weights='distance'),\n",
        "\n",
        "    # Gradient Boosting - par√¢metros leves conforme aula\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
        "        n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42\n",
        "    ),\n",
        "\n",
        "    # AdaBoost - taxa de aprendizado menor\n",
        "    \"AdaBoost\": AdaBoostClassifier(\n",
        "        n_estimators=100, learning_rate=0.5, random_state=42\n",
        "    ),\n",
        "\n",
        "    # HistGradientBoosting - mais itera√ß√µes e taxa menor\n",
        "    \"HistGradientBoosting\": HistGradientBoostingClassifier(\n",
        "        max_iter=150, learning_rate=0.05, max_depth=5, random_state=42\n",
        "    ),\n",
        "\n",
        "    # RidgeClassifier - regulariza√ß√£o leve\n",
        "    \"RidgeClassifier\": RidgeClassifier(alpha=1.0),\n",
        "\n",
        "\n",
        "    # XGBoost - par√¢metros t√≠picos de equil√≠brio (aula 15 parte 4)\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        eval_metric='logloss', n_estimators=150, learning_rate=0.05,\n",
        "        max_depth=5, subsample=0.8, colsample_bytree=0.8, random_state=42\n",
        "    ),\n",
        "\n",
        "    # CatBoost - taxa de aprendizado reduzida e itera√ß√µes extras\n",
        "    \"CatBoost\": CatBoostClassifier(\n",
        "        iterations=150, learning_rate=0.05, depth=5,\n",
        "        verbose=0, random_state=42\n",
        "    ),\n",
        "\n",
        "    # LightGBM - profundidade controlada e taxa moderada\n",
        "    \"LightGBM\": LGBMClassifier(\n",
        "        n_estimators=150, learning_rate=0.05,\n",
        "        num_leaves=31, max_depth=6, random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "\n",
        "# Valida√ß√£o cruzada\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "# M√©tricas\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, zero_division=0),\n",
        "    'recall': make_scorer(recall_score, zero_division=0),\n",
        "    'f1': make_scorer(f1_score, zero_division=0),\n",
        "    'roc_auc': make_scorer(roc_auc_score)\n",
        "}\n",
        "\n",
        "# Treinamento\n",
        "resultados = []\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "    print(f\"Treinando modelo: {nome}...\")\n",
        "    try:\n",
        "        pipeline = Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"clf\", modelo)\n",
        "        ])\n",
        "\n",
        "        scores = cross_validate(pipeline, X, y, cv=tscv, scoring=scoring)\n",
        "\n",
        "        resultados.append({\n",
        "            \"Modelo\": nome,\n",
        "            \"Accuracy\": scores['test_accuracy'].mean(),\n",
        "            \"Precision\": scores['test_precision'].mean(),\n",
        "            \"Recall\": scores['test_recall'].mean(),\n",
        "            \"F1-score\": scores['test_f1'].mean(),\n",
        "            \"ROC AUC\": scores['test_roc_auc'].mean(),\n",
        "        })\n",
        "\n",
        "        print(f\" Modelo {nome} treinado com sucesso.\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Erro ao rodar o modelo {nome}: {e}\\n\")\n",
        "\n",
        "# Resultado final\n",
        "df_resultados = pd.DataFrame(resultados).sort_values(\"F1-score\", ascending=False)\n",
        "df_resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "rUzXxt75rsv5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}